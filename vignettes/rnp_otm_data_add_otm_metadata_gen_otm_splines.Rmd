---
title: "Dealing with OTM data"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all()
```

## Overview

The goal of this vignette is to illustrate the process behind the functions `rnp_otm_data`, `add_otm_metadata` and `gen_otm_splines` of the `throne` package. The first two functions allow for the reading and processing of multiple raw `.csv` files with the temperature measurements recorded using **operative temperature models** (**OTM**) to data frame-like structure in `R` (i.e., a [`tibble`](https://tibble.tidyverse.org/)). The `gen_otm_splines` function will then take this processed OTM data and generate OTM & date specific cubic spline models that describe the thermal dynamics of each OTM each day. These spline models will later be used to both correct the flight data and to ultimately predict thermal landscapes. Below, we highlight the section of the package's workflow that is covered in this vignette

## Reading and processing raw OTM data

The `rnp_otm_data` function (i.e., **r**ead a**n**d **p**rocess OTM data) reads a reads and combines data from a set of raw OTM files (`.csv` format) and transforms them into an `R` `tibble`. Below we detail the function's inputs, processing and outputs.

### Inputs

The `rnp_otm_data` function takes in 4 inputs:

1.  `folder_path`: A character indicating the location where all OTM `.csv` files are stored.
2.  `rows_skip`: An integer indicating how many rows should be skipped when reading each `.csv` file.
3.  `time_col`: An integer indicating the column in all `.csv` that corresponds to the time associated with each recording
4.  `op_temp-col`: An integer indicating the column in all `.csv` that corresponds to the operative temperature measurement.

While the specific way in which of these arguments is used to process the data will be discussed next, we want to take a second to highlight the importance of the `rows_skip` argument here. Including the it ensures that reading errors will be minimized. For instance, the software we used to program and download the data recorded in the Eye Buttons that we house inside the OTMs is [OneWire Viewer](https://www.analog.com/en/resources/evaluation-hardware-and-software/1-wire-sdks/viewer.html) returns `.csv` files with several rows of metadata on each measurement. These rows lead to an incorrect reading of the raw data, see below:

```{r, eval = FALSE}
read.csv("data/otm_data/OTM34.csv")
```

```{r, echo = FALSE}
head(read.csv("C:/Users/ggarc/OneDrive/research/throne/data/otm_data/OTM34.csv"), 15)
```

In contrast, by skipping precisely `14` rows, we can access the recordings directly without formatting issues:

```{r, eval = FALSE}
read.csv("data/otm_data/OTM34.csv", skip = 14)
```

```{r, echo = FALSE}
head(read.csv("C:/Users/ggarc/OneDrive/research/throne/data/otm_data/OTM34.csv", skip = 14))
```

> **TIP**: We recommend that users of the `throne` package become very familiar with the formatting of the raw OTM data. Specifying the `rows_skip` argument correctly is crucial for the rest of the package's functions to work properly down the line.

### Processing

To transform the raw `.csv` data into an `R` `tibble`, the `rnp_otm_data` function will go through the following general steps for each of the files contained in the folder specified via the argument `folder_path`:

1.  Read each `.csv` file while skipping as many rows as specified within the `rows_skip` argument.
2.  Select the columns for time and operative temperature as specified by the `time_col` and `op_temp_col` arguments.
3.  Using tools from the `lubridate` package, extract the year, Julian date and minute of the day for each operative temperature measurement.

> **NOTE**: We choose to use Julian dates and minutes of the day to simplify the management of the data as much as possible. Date and time data have unique data formats in the `R` environment that are often difficult to handle for users and that might lead to unintended errors. By using Julian dates and minutes of the day, we deal only with integer columns, much easier to operate with and manipulate. Further, these formats can be easily transformed back into more easily interpretable scales for visualization purposes, [by using the `as.Date` function to transform Julian dates back into a YYYY-MM-DD format](https://stackoverflow.com/questions/24200014/convert-day-of-year-to-date) and dividing by 60 for minutes of the day to get hours.

> **ALSO NOTE**: OneWire Viewer, returns `.csv` files that have a MM/DD/YY HH:MM:SS format. Data in this data format can be translated into a time column using the `mdy_hms` function of the `lubridate` package. Please note that the time column of any raw OTM dataset to be in this format for the `rnp_otm_data` to function correctly.

### Outputs

The final output is a `tibble` object with columns for the OTM's identification (`otm_id`), year, date (Julian date format), minute of the day (`minute`) and operative temperature (`op_temp`). If the function worked correctly, the resulting data set should contain all observations made by all OTM whose files were located in the directory specified via the argument `folder_path`. We have included a data set of these characteristics with 33 OTMs that recorded over a period of 4 days. Below we present and plot a subset of this data:

```{r, echo = FALSE, message = FALSE, fig.height=4, fig.width=8}
otm_data <- rnp_otm_data(folder_path = "C:/Users/ggarc/OneDrive/research/throne/data/otm_data", rows_skip = 14, time_col = 1, op_temp_col = 3)
head(otm_data)

otm_data %>% 
  filter(date %in% c(235, 236)) %>%
  mutate(date = ifelse(date == 235, "DOY 235 (August 23rd)", "DOY 236 (August 24th)")) %>%
  ggplot(aes(x = minute/60, y = op_temp)) +
  geom_line(aes(group = otm_id), linewidth = 0.5, alpha = 0.25) +
  xlab("Hour of the day") + ylab("Operative Temperature (°C)") +
  scale_x_continuous(expand = c(0,0)) +
  facet_wrap(~date) +
  theme_minimal() +
  theme(panel.border = element_rect(fill =NA),
        axis.ticks = element_line(),
        strip.text = element_text(size = 12))
  
```

## Adding OTM metadata

The `add_otm_metadata` function adds information about the OTMs to the OTM data frame obtained using the `rnp_otm_data` function.The function takes in 2 inputs:

1.  `otm_data`: The OTM data frame obtained using the `rnp_otm_data` function
2.  `otm_metadata`: An OTM metadata file

As part of the `throne` package documentation we include an example metadata file for OTM. Our file contains information on the latitude, longitude and elevation at which each OTM was deployed as well as information on the orientation and microhabitat.

```{r}
otm_metadata <- read.csv("C:/Users/ggarc/OneDrive/research/throne/data/otm_metadata.csv")
head(otm_metadata)
```

The `add_otm_metadata` then simply merges the original OTM data frame with the OTM metadata by OTM identity. Leading to a data frame with additional columns:

```{r, echo = FALSE, message=FALSE,  fig.height=4, fig.width=8}
otm_data <- add_otm_metadata(otm_data = otm_data, otm_metadata = otm_metadata)
head(otm_data)

otm_data %>% 
  filter(date %in% c(235, 236)) %>%
  mutate(date = ifelse(date == 235, "DOY 235 (August 23rd)", "DOY 236 (August 24th)")) %>%
  ggplot(aes(x = minute/60, y = op_temp)) +
  geom_point(aes(group = otm_id, col = orientation), size = 0.5, alpha = 0.1) +
  geom_smooth(aes(col = orientation, fill = orientation)) +
  xlab("Hour of the day") + ylab("Operative Temperature (°C)") +
  scale_x_continuous(expand = c(0,0)) +
  facet_wrap(~date) +
  theme_minimal() +
  theme(panel.border = element_rect(fill =NA),
        axis.ticks = element_line(),
        strip.text = element_text(size = 12))
```

This makes the `add_otm_metadata` function extremely versatile to use as the user can incorporate as much metadata to their OTMs ad needed (e.g., their size o their color if different OTM shapes are deployed simultaneously etc.).

## Generating OTM spline models

The last step when dealing with OTM data is to fit a **cubic smoothing spline model** to each individual OTM for each day during it's deployment in the field. This spline model will capture the thermal dynamics of the OTM throughout a given day. In turn this allows us to predict the temperature the OTM experiences in any moment of the day based on the observations it recorded during that day.

To fit these models the `throne` package includes the `gen_otm_splines` function (**Gen**erate **OTM** cubic smoothing **splines** model). This function takes in an OTM data frame that has been generate via the `rnp_otm_data` and `add_otm_metadata` functions and returns a complex `tibble`. This `tibble` will include the OTM's identification and all associated metadata, together with a [nested column](https://tidyr.tidyverse.org/articles/nest.html) containing the spline model generated via the native `R` function `smooth.spline`. We call this a complex `tibble` precisely because of the nesting of the `splines` column. The resulting splines `tibble` will contain as many rows as combinations of unique `otm_id` and `date` since there will be a spline model for each OTM every day it was deployed in the field:

```{r, echo = FALSE}
load("C:/Users/ggarc/OneDrive/research/throne/data/otm_splines.RData")
otm_splines
```

A critical point for the `gen_otm_splines` function to work correctly is determining the appropriate value for the `knot_p` argument. This argument determines the percentage of observations recorded by an OTM in a given day that are used to determine the number of knots of the smoothing spline model. In short, the number of knots will ultimately determine the degrees of freedom of the model as $df = degree + k$ and $degree = 3$ for cubic splines. (see [here](https://stats.stackexchange.com/questions/517375/splines-relationship-of-knots-degree-and-degrees-of-freedom#:~:text=In%20essence%2C%20splines%20are%20piecewise,degree%203%20and%20so%20on.) for further details). The number of degrees of freedom will then determine the "wiggliness" of the resulting model, in other words, the number of times the resulting curve will change direction. As an example, below we plot different spline models for the same data using different `knot_p` parameter specifications.

```{r, echo = FALSE, message=FALSE, fig.width=6, fig.height = 4, fig.align='center'}
# filter specific otm id data
otm_data_id <- otm_data %>% filter(otm_id == "OTM01", date == 235)

# generate OTM splines
otm_splines_96 <- gen_otm_splines(otm_data = otm_data_id, knot_p = 96/720)
otm_splines_48 <- gen_otm_splines(otm_data = otm_data_id, knot_p = 48/720)
otm_splines_12 <- gen_otm_splines(otm_data = otm_data_id, knot_p = 12/720)
otm_splines_6 <- gen_otm_splines(otm_data = otm_data_id, knot_p = 6/720)

# generate data
otm_splines_96 <- as.data.frame(predict(otm_splines_96$splines[[1]])) %>%
  rename(minute = x, op_temp = y) %>% mutate(knot_p = 96/720)
otm_splines_48 <- as.data.frame(predict(otm_splines_48$splines[[1]])) %>%
  rename(minute = x, op_temp = y) %>% mutate(knot_p = 48/720)
otm_splines_12 <- as.data.frame(predict(otm_splines_12$splines[[1]])) %>%
  rename(minute = x, op_temp = y) %>% mutate(knot_p = 12/720)
otm_splines_6 <- as.data.frame(predict(otm_splines_6$splines[[1]])) %>%
  rename(minute = x, op_temp = y) %>% mutate(knot_p = 6/720)
otm_pred <- rbind(otm_splines_96, otm_splines_48, otm_splines_12, otm_splines_6)

# plot
ggplot() +
  geom_point(data = otm_data_id, aes(x = minute/60, y = op_temp), size = 3, alpha = 0.1) +
  geom_line(data = otm_pred, aes(x = minute/60, y = op_temp, col = as.factor(round(knot_p, digits = 3))),
            alpha = 0.75, linewidth = 1.25) +
  scale_x_continuous(expand = c(0,0)) +
  xlab("Hour of the day") +
  ylab("Operative Temperature (°C)") +
  theme_minimal() +
  theme(panel.border = element_rect(linewidth = 0.5, fill = NA),
        strip.background = element_rect(linewidth = 0.5, fill = "lightgray"),
        strip.text = element_text(size = 12)) +
  guides(color = guide_legend(title = "knot_p")) +
  ggtitle("OTM01 on DOY 235 (August 23rd)")
```

The decision on which `knot_p` value to use is dependent on two things. First is the **frequency at which the OTM itself is recording**. We can extrapolate how many knots/day (or knots/h) we would get based on the frequency of recordings and the `knot_p` value according to the formula:

$$ Knot/h = Recordings/h \cdot knot_p$$

For instance, the OTMs we used here were programmed to record a temperature measurement every 2 minutes, leading to a total of 30 observations per OTM/hour. Assuming a `knot_p = 0.1` that would indicate that our model has 3 knots / h.

The second issue that determines the value of `knot_p` is the study organism of the user of this `R` package. Generally OTMs will equilibrate to the environmental temperature much faster than the organism they represent with this difference in equilibration time being positively correlated to the mass of the organism due to thermal inertia. In other words, the body temperature of an organism that has a lot of thermal inertia will not be exactly that of the OTM.

(Need some more work on this)
